论文：
    框架：
        常见推荐算法：
            盖常规推荐、序列推荐、引入知识图谱的推荐、引入时间动态性的推荐
        常见数据集：
            购物：amazon
            视频：Movielens

        框架流程：
             图中最底层是 Preprocessing 层, 主要作用是将现有的公开数据(例如Amazon[7]和 MovieLens[8])转换成固定格式的输入文件. 
             Reader 层在 Preprocessing 层之上, 对固定格式的文件进行读入、整合和处理, 提取出核心数据以及相关的统计量, 并以 DataFrame 的形式提供给 Model 层. 
             Model层负责推荐算法的具体实现, 包括模型输入的准备、参数定义、前向传播、损失函数计算等等. 
             Runner 层控制训练和测试的流程, 并且负责设置训练的参数、多线程准备 batch、统计训练结果等
                fit 负责每一轮的训练并返回当前轮次的 loss; 
                train 控制总体的训练过程, 进行每一轮迭代训练、记录验证集结果、判断是否需要early stop、输出训练信息等; 
                predict 负责对给定候选商品给出排序分数; 
                evaluate 则根据分数计算各种排序评价指标. 
    复现论文：
        题目：自监督的图神经网络用于序列推荐
        注重短期交互信息，并降低相应的噪声
        序列推荐：分析近期交互行为，预测未来的行为
        问题：
            只关注单一用户，忽视有关联的用户
            要求数据集的高质量，忽视现实中的数据集是噪声的
        贡献：
            动态合作交互信息
            短时间降噪
        定义：
            u：用户
            v：物品
            adj：相邻矩阵，用户和物品的交互时间段
            多种损失：
                L_rec：预测结果和gt的loss
                L_sal：SSL(自监督目标)，用于对齐短时间嵌入E_s和长时间嵌入E_l
                需要信息：
                    预测f：预测结果，根据E_s和E_l和f的参数
                    预测g：预测E_s和E_l，根据g的参数

原始复现方法：
    数据集：提供了处理.csv文件处理为四个文件的代码
        |--- sequence    # user behavior sequences (List)
            含义：用户行为序列列表
            内容：每个用户的历史交互序列，通常按时间顺序排列
        |--- test_dict    # test item for each users (Dict)
            含义：测试集字典
            内容：以用户ID为key，对应的测试物品列表为value
        |--- trn_mat_time    # user-item graphs in different periods (sparse matrix)
            含义：按时间段划分的训练用户-物品交互矩阵
            内容：稀疏矩阵形式，可能包含时间戳信息，用于时序推荐
        |--- tst_int    # users to be test (List)
            含义：测试用户列表
            内容：需要进行测试评估的用户ID列表

        通过args.data传入，已经给出生成好的上面4个，如果使用自己的数据，需要看代码如何对数据进行过滤
        生成好上面4个是二进制文件，以pickle.load读入
    模型：
        加载模型args.load_model，用于加载预训练模型的

    1. 原模型的流程：
        # 构造4个文件并读取
        handler = DataHandler()
	    handler.LoadData()

        with tf.Session(config=config) as sess:
            recom = Recommender(sess, handler)
            # 这里包含了准备模型和训练模型，在下面的框架应该分开
            recom.run()
    2. 框架的流程：
        # 使用reader读取并保存为.pkl格式的数据
        corpus = reader_name(args)
        
        # 创建模型并统计参数量
        model = model_name(args, corpus).to(args.device)
	    logging.info('#params: {}'.format(model.count_variables()))

        # 好像论文没有dev
        # 直接忽略掉这个函数，因为数据集好像是采样得到的，不是直接固定的
        for phase in ['train', 'dev', 'test']:
            data_dict[phase] = model_name.Dataset(model, corpus, phase)
            data_dict[phase].prepare()

        # 使用runner运行模型
        # 要在初始化的时候加载模型
        runner = runner_name(args)
        logging.info('Test Before Training: ' + runner.print_res(data_dict['test']))
        if args.load > 0:
            model.load_model()
        if args.train > 0:
            # 从data_dict中加载模型
		    runner.train(data_dict)

        # 测评
        eval_res = runner.print_res(data_dict['dev'])
        # 模型后的操作
        model.actions_after_train()

框架复现思路：

python main.py \
    --data amazon \
    --reg 1e-2 \
    --lr 1e-3 \
    --temp 0.1 \
    --ssl_reg 1e-6 \
    --save_path amazon \
    --epoch 150  \
    --batch 512 \
    --sslNum 80 \
    --graphNum 5  \
    --pred_num 0 \
    --gnn_layer 3 \
    --test True \
    --att_layer 4 \
    --testSize 1000 \
    --keepRate 0.5 \
    --sampNum 40 \
    --pos_length 200 
执行命令
    cd D:\A1111\School\中大课件\大三上\机器学习实验\大作业\ReChorus\src
    python main.py --model_name SelfGNN --dataset amazon --path Datasets \
                    --data amazon \
                    --reg 1e-2 \
                    --lr 1e-3 \
                    --temp 0.1 \
                    --ssl_reg 1e-6 \
                    --save_path amazon \
                    --epoch 150  \
                    --batch 512 \
                    --sslNum 80 \
                    --graphNum 5  \
                    --pred_num 0 \
                    --gnn_layer 3 \
                    --test True \
                    --att_layer 4 \
                    --testSize 1000 \
                    --keepRate 0.5 \
                    --sampNum 40 \
                    --pos_length 200 

    python main.py --model_name SelfGNN --dataset amazon --path Datasets  --data amazon  --reg 1e-2  --lr 1e-3  --temp 0.1  --ssl_reg 1e-6  --save_path amazon  --epoch 150   --batch 512  --sslNum 80  --graphNum 5   --pred_num 0  --gnn_layer 3  --test True  --att_layer 4  --testSize 1000  --keepRate 0.5  --sampNum 40  --pos_length 200 

环境安装：
    python=3.6.12
    pip install matplotlib
    pip install numpy
    pip install scipy
    pip install tensorflow_gpu==1.15.0
    pip install pandas
    pip install torch
    pip install tqdm
    pip install scikit-learn
    pip install pyyaml
    pip install scipy


和模型中同框架的模型进行对比
    GRU4Rec（有）
        python src/reproduce.py --model_name GRU4Rec --emb_size 64 --hidden_size 100 --lr 1e-3 --l2 1e-4 --history_max 20 --dataset Grocery_and_Gourmet_Food
    
        python src/reproduce.py --model_name GRU4Rec --emb_size 64 --hidden_size 100 --lr 1e-3 --l2 1e-4 --history_max 20 --dataset MovieLens_1M
    
    TiSASRec（有）
        python src/reproduce.py --model_name TiSASRec --emb_size 64 --num_layers 1 --num_heads 1 --lr 1e-4 --l2 1e-6 --history_max 20 --dataset Grocery_and_Gourmet_Food
        
        python src/reproduce.py --model_name TiSASRec --emb_size 64 --num_layers 1 --num_heads 1 --lr 1e-4 --l2 1e-6 --history_max 20 --dataset MovieLens_1M

使用框架中的数据集
    Grocery_and_Gourmet_Food
    MovieLens_1M

论文中使用的数据集：
    amazon：2014年
    gowalla：2010年
    movielens：2002-2009
    yelp：2009-2019

数据集的转换：
    计划将框架的数据集通过预处理成为论文的数据集，但是又不能直接用，因为论文的数据集是将dev放到序列的最后一个，但是框架将三个数据集分开了

    或者通过处理，将框架是数据集构造成论文的形式，论文里dev和test使用相同的负样本，由于框架中使用不同数量的负样本采样，可能需要修改数量，可以设置args.test_size实现
    python main.py --data grocery --reg 1e-2 --lr 1e-3 --temp 0.1 --ssl_reg 1e-6 --save_path grocery --epoch 150  --batch 64 --sslNum 80 --graphNum 5  --pred_num 0 --gnn_layer 3 --test True --att_layer 4 --testSize 100 --keepRate 0.5 --sampNum 40 --pos_length 200

论文：
摘要：
    序列推荐强调用户短期的序列交互
    为了克服监督的限制，出现自监督用于推荐系统
    仍有两个挑战：
        关注长期序列，忽视短期
        短期序列存在噪声
    通过时间间隔编码时间图，使用GNN学习短期时间交互
    通过时间间隔融合和动态建模学习长期交互
    增强的自监督学习框架增强对短期噪声的鲁棒性
1. 介绍
    推荐系统解决信息过载问题
    挑战：
        目前只关注单用户，忽视一段时间内，群体用户的一致性的行为
        好的结果依赖高质量数据，忽略现实数据存在大量噪声，现有结果依赖随机噪声增强，可能会限制对用户表征的学习
    贡献：
        动态的协同信息
            1. 短期协同图编码
                分成多个时间间隔，使用GCN传播捕捉高阶信息
            2. 多级长期序列学习
                两级序列建模学习，相互学习
                不同时间间隔的短期特征视作序列生成用户的长期协同特征
                完整的用户序列用自注意力机制建模
        3. 个性化的自增强学习降噪
            用长期用户兴趣修正短期时间图
            为每个用户学习个性化的权重，并以此调整噪声水平
            用以区分短期噪声
2. 相关工作
    图神经网络应用于推荐
    序列推荐系统
    自监督的推荐系统
3. 方法
    GNN捕捉高阶协同关系
    自监督捕捉用户偏好转变
    根据可调整的超参数T均分时间序列，交互过为1，否则为0
        用所有的A_{t_i}，预测A_{T+1}
        L_rec比较预测和gt的差距
        L_sal比较长期嵌入和短期嵌入的损失
            预测=f(长期嵌入，短期嵌入)
            长期嵌入，短期嵌入 = 编码器g(A_t)
    1. 短期协同图编码
        将用户和物品映射到，不同时隙，的d维向量
        followLightGCN，使用简化的GCN建模短期图，获得每个用户、物品的邻居中心聚集，并随机丢弃防止过拟合
        使用GNN进行L层的信息传播，最后将所有层进行拼接，用于后面的GRU
    2. 多级长期序列学习
        1. 时间间隔级别的序列模式的建模（创新）
            用捕捉阶段变化的暂时注意力，融合短期特征到长期嵌入
            使用GRU网络而不是位置编码，因为位置编码对小的T太简单了
            将GRU的所用隐藏层使用多头注意力机制提取动态特征
            将所有时间间隔平均得到最后的长期特征
        2. 实例级别的序列模式的建模
            保留注意力的使用
            组合用户的交互行为，物品的嵌入向量和位置编码
            使用L_a层的注意力机制，然后求和得到用户的实例级别的序列交互
        3. 多视图的融合和预测
            预测和L_rec损失
        4. 个性化降噪自增强
            为了减轻数据稀疏性和噪声问题
            过滤与用户长期偏好不一致的短期行为
            不同用户有不同的强度
            从短期图中采样两个已经观察到的行为，均计算：
                计算时间间隔的似然
                计算长期的似然
                每个用户有一个长期的权重系数
            得到L_sal

4. 消融实验
    短期学习：全局交互时间表（已完成）
    长期学习：移除基于注意力的实例级别的序列模式（-ATL）
    个性化降噪自增强：移除自增强范式（-SAL）

